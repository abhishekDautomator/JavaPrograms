Implementing a **rate limiter** in a microservice is essential for protecting your service from abuse, ensuring fair usage, and maintaining performance ‚Äî especially in high-traffic environments like e-commerce or public APIs.

Here‚Äôs a breakdown of how to do it, with examples tailored for your Java/Spring/Quarkus expertise.

---

## üö¶ What Is Rate Limiting?

Rate limiting controls how many requests a client can make to your service within a given time window.
It helps:
- Prevent **Denial-of-Service (DoS)** attacks
- Ensure **fair resource allocation**
- Protect **downstream services** from overload

---

## üß∞ Common Strategies

| Strategy            | Description                                                                 |
|---------------------|-----------------------------------------------------------------------------|
| Token Bucket        | Tokens are added at a fixed rate; requests consume tokens.                  |
| Leaky Bucket        | Requests are processed at a fixed rate; excess is discarded or delayed.     |
| Fixed Window        | Count requests per time window (e.g., 100 req/min).                         |
| Sliding Window      | More accurate version of fixed window using rolling timestamps.             |

---

## ‚úÖ Example 1: Rate Limiting in Quarkus Using `@RateLimit` (with SmallRye Fault Tolerance)

Quarkus supports rate limiting via annotations:

```java
import io.smallrye.faulttolerance.api.RateLimit;
import jakarta.ws.rs.GET;
import jakarta.ws.rs.Path;

@Path("/limited")
public class RateLimitedResource {

    @GET
    @RateLimit(value = 5, window = 1) // max 5 requests per second
    public String limitedEndpoint() {
        return "Allowed!";
    }
}
```

### üîç How It Works:
- `value = 5`: max 5 requests
- `window = 1`: per second
- If exceeded, requests are rejected with `429 Too Many Requests`

---

## ‚úÖ Example 2: Custom Rate Limiter Using Guava

```java
import com.google.common.util.concurrent.RateLimiter;

public class RateLimitedService {
    private final RateLimiter limiter = RateLimiter.create(10.0); // 10 permits/sec

    public String handleRequest() {
        if (limiter.tryAcquire()) {
            return "Processed";
        } else {
            return "Rate limit exceeded";
        }
    }
}
```

---

## ‚úÖ Example 3: API Gateway-Based Rate Limiting (Spring Cloud Gateway or Kong)

Rate limiting is often implemented at the **API Gateway layer** to centralize control:

### Spring Cloud Gateway YAML config:
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: rate_limited_route
          uri: http://localhost:8080
          predicates:
            - Path=/api/**
          filters:
            - name: RequestRateLimiter
              args:
                redis-rate-limiter.replenishRate: 5
                redis-rate-limiter.burstCapacity: 10
```

Requires Redis for distributed rate limiting.

---

## üß™ Best Practices

- Use **distributed stores** (Redis, Hazelcast) for multi-instance rate limiting
- Return proper HTTP status codes (`429 Too Many Requests`)
- Include **Retry-After** headers
- Monitor and log rate limit violations


In a **Spring Boot** application, implementing a rate limiter can be done in several ways depending on your architecture. Here's a breakdown of the most effective approaches, with examples:

---

## ‚úÖ 1. **Using Bucket4j (In-Memory or Distributed)**

Bucket4j is a popular Java library for token bucket rate limiting.

### üîß Maven Dependency:
```xml
<dependency>
    <groupId>com.github.vladimir-bukhtoyarov</groupId>
    <artifactId>bucket4j-core</artifactId>
    <version>8.2.0</version>
</dependency>
```

### üß© Example: Simple In-Memory Rate Limiter
```java
import io.github.bucket4j.Bandwidth;
import io.github.bucket4j.Bucket;
import io.github.bucket4j.Refill;
import org.springframework.web.bind.annotation.*;

import java.time.Duration;

@RestController
@RequestMapping("/api")
public class RateLimitedController {

    private final Bucket bucket = Bucket.builder()
        .addLimit(Bandwidth.classic(5, Refill.intervally(5, Duration.ofSeconds(1))))
        .build();

    @GetMapping("/limited")
    public String limitedEndpoint() {
        if (bucket.tryConsume(1)) {
            return "Request accepted";
        } else {
            return "Too many requests";
        }
    }
}
```

---

## ‚úÖ 2. **Using Spring Cloud Gateway + Redis**

For distributed rate limiting across instances, use Spring Cloud Gateway with Redis.

### üîß Add Dependencies:
```xml
<dependency>
    <groupId>org.springframework.cloud</groupId>
    <artifactId>spring-cloud-starter-gateway</artifactId>
</dependency>
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-data-redis-reactive</artifactId>
</dependency>
```

### ‚öôÔ∏è YAML Configuration:
```yaml
spring:
  cloud:
    gateway:
      routes:
        - id: rate_limited_route
          uri: http://localhost:8080
          predicates:
            - Path=/api/**
          filters:
            - name: RequestRateLimiter
              args:
                redis-rate-limiter.replenishRate: 5
                redis-rate-limiter.burstCapacity: 10
```

---

## ‚úÖ 3. **Using Resilience4j RateLimiter**

Resilience4j integrates with Spring Boot and supports annotations.

### üîß Maven Dependency:
```xml
<dependency>
    <groupId>io.github.resilience4j</groupId>
    <artifactId>resilience4j-spring-boot2</artifactId>
</dependency>
```

### ‚öôÔ∏è Configuration:
```yaml
resilience4j:
ratelimiter:
  instances:
    myLimiter:
      limitForPeriod: 5
      limitRefreshPeriod: 1s
      timeoutDuration: 0
```

### üß© Usage:
```java
import io.github.resilience4j.ratelimiter.annotation.RateLimiter;
import org.springframework.web.bind.annotation.*;

@RestController
public class ResilienceController {

    @GetMapping("/resilient")
    @RateLimiter(name = "myLimiter")
    public String resilientEndpoint() {
        return "Allowed by Resilience4j";
    }
}
```

---

## üß† Best Practices

- Use **Redis** or **Hazelcast** for distributed rate limiting
- Return proper HTTP status codes (`429 Too Many Requests`)
- Include `Retry-After` headers
- Monitor rate limit metrics